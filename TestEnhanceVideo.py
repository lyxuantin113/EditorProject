import cv2
import numpy as np
from gfpgan import GFPGANer
from PIL import Image

# ========== C·∫§U H√åNH ==========
video_path = 'datasets/v2.mp4'  # Video ƒë·∫ßu v√†o
output_path = 'datasets/v2_enhanced.mp4'  # Video ƒë·∫ßu ra
GFPGAN_MODEL_PATH = 'GFPGAN/experiments/pretrained_models/GFPGANv1.4.pth'

# ========== KH·ªûI T·∫†O ==========
gfpgan = GFPGANer(
    model_path=GFPGAN_MODEL_PATH,
    upscale=1,
    arch='clean',
    channel_multiplier=2,
    bg_upsampler=None
)

cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print(f"‚ùå Kh√¥ng m·ªü ƒë∆∞·ª£c video: {video_path}")
    exit()

fps = cap.get(cv2.CAP_PROP_FPS)
frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

print(f"üîÑ FPS: {fps}, K√≠ch th∆∞·ªõc: {frame_w}x{frame_h}")

# C·∫•u h√¨nh codec ƒë·ªÉ xu·∫•t ra .mp4
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, (frame_w, frame_h))

frame_idx = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame_idx += 1
    print(f"üîß ƒêang x·ª≠ l√Ω frame {frame_idx}...")

    try:
        # Convert BGR ‚Üí RGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Ch·∫°y GFPGAN
        _, _, restored_frame = gfpgan.enhance(
            frame_rgb,
            has_aligned=False,
            only_center_face=True,
            paste_back=True
        )

        # N·∫øu tr·∫£ v·ªÅ list th√¨ l·∫•y frame ƒë·∫ßu
        if isinstance(restored_frame, list):
            restored_frame = restored_frame[0]

        # Convert RGB ‚Üí BGR ƒë·ªÉ ghi video
        frame_bgr = cv2.cvtColor(restored_frame, cv2.COLOR_RGB2BGR)

        # Resize l·∫°i n·∫øu kh√¥ng kh·ªõp (ph√≤ng l·ªói ghi)
        if frame_bgr.shape[1] != frame_w or frame_bgr.shape[0] != frame_h:
            frame_bgr = cv2.resize(frame_bgr, (frame_w, frame_h))

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói t·∫°i frame {frame_idx}: {e}")
        frame_bgr = frame  # D√πng frame g·ªëc n·∫øu l·ªói

    out.write(frame_bgr)

cap.release()
out.release()
print(f"‚úÖ Video ƒë√£ x·ª≠ l√Ω xong v√† l∆∞u t·∫°i: {output_path}")
