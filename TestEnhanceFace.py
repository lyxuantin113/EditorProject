from PIL import Image
import torch
from facenet_pytorch import MTCNN
from gfpgan import GFPGANer
import numpy as np
import cv2
import os

# ========== Cáº¤U HÃŒNH ==========
INPUT_IMAGE = 'oldimg1.jpg'
OUTPUT_IMAGE = 'ImagesEnhanced/' + INPUT_IMAGE + '_enhanced.jpg'
GFPGAN_MODEL_PATH = 'GFPGAN/experiments/pretrained_models/GFPGANv1.4.pth'  # Äáº·t Ä‘Æ°á»ng dáº«n model táº¡i Ä‘Ã¢y

# ========== KHá»I Táº O ==========
device = 'cuda' if torch.cuda.is_available() else 'cpu'

print(f"Using device: {device}")

# Khá»Ÿi táº¡o face detector
mtcnn = MTCNN(keep_all=True, device=device)

# Khá»Ÿi táº¡o GFPGAN
gfpgan = GFPGANer(
    model_path=GFPGAN_MODEL_PATH,
    upscale=1,
    arch='clean',
    channel_multiplier=2,
    bg_upsampler=None
)

# ========== Äá»ŒC áº¢NH ==========
image = Image.open(INPUT_IMAGE).convert('RGB')
image_np = np.array(image)

# ========== PHÃT HIá»†N KHUÃ”N Máº¶T ==========
boxes, _ = mtcnn.detect(image)

if boxes is None:
    print("KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t nÃ o.")
    exit()

# ========== Xá»¬ LÃ Tá»ªNG KHUÃ”N Máº¶T ==========
for i, box in enumerate(boxes):
    pad = 20  # hoáº·c 30 tÃ¹y áº£nh
    x1, y1 = max(0, int(box[0] - pad)), max(0, int(box[1] - pad))
    x2, y2 = min(image_np.shape[1], int(box[2] + pad)), min(image_np.shape[0], int(box[3] + pad))

    # Kiá»ƒm tra giá»›i háº¡n
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(image_np.shape[1], x2), min(image_np.shape[0], y2)

    # Crop khuÃ´n máº·t
    face_crop = image_np[y1:y2, x1:x2].copy()
    print(f"Processing face {i} at box: ({x1},{y1})-({x2},{y2}), size: {face_crop.shape}")
    cv2.imwrite(f"debug_face_{i}.png", cv2.cvtColor(face_crop, cv2.COLOR_RGB2BGR))

    # Sá»­ dá»¥ng GFPGAN Ä‘á»ƒ lÃ m nÃ©t
    _, _, restored_face = gfpgan.enhance(
        face_crop, has_aligned=False, only_center_face=True, paste_back=True
    )

    if restored_face is None:
        print(f"âš ï¸ KhÃ´ng thá»ƒ xá»­ lÃ½ khuÃ´n máº·t táº¡i box {i}. Bá» qua...")
        continue

    # Resize láº¡i cho khá»›p kÃ­ch thÆ°á»›c gá»‘c
    enhanced_face = Image.fromarray(restored_face)
    enhanced_face = enhanced_face.resize((x2 - x1, y2 - y1))

    # GhÃ©p láº¡i áº£nh gá»‘c
    image.paste(enhanced_face, (x1, y1))

# ================= RESTORE TOÃ€N áº¢NH =================
print("\nğŸ§¯ Äang khÃ´i phá»¥c toÃ n bá»™ áº£nh (restore full image)...")

# DÃ¹ng áº£nh gá»‘c (khÃ´ng crop), xá»­ lÃ½ full face
_, _, restored_img = gfpgan.enhance(
    image_np, has_aligned=False, only_center_face=False, paste_back=False
)

# LÆ°u káº¿t quáº£ khÃ´i phá»¥c toÃ n áº£nh
if restored_img is not None and isinstance(restored_img, list) and len(restored_img) > 0:
    Image.fromarray(restored_img[0]).save('dx_restored_full.jpg')
    print("âœ”ï¸ áº¢nh Ä‘Ã£ Ä‘Æ°á»£c khÃ´i phá»¥c toÃ n diá»‡n: dx_restored_full.jpg")
else:
    print("âš ï¸ KhÃ´ng thá»ƒ khÃ´i phá»¥c áº£nh toÃ n diá»‡n.")


# ========== LÆ¯U áº¢NH ==========
image.save(OUTPUT_IMAGE)
print(f"âœ”ï¸ áº¢nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {OUTPUT_IMAGE}")
